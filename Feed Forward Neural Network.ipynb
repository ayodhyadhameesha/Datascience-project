{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "#importing needed packages\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.mlab as mlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.load('data.npy', allow_pickle=True)\n",
    "target=np.load('target.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5034, 8)\n",
      "(5034,)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=target.reshape(-1, 1)\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "scaler_x.fit(data)\n",
    "scaler_y.fit(target)\n",
    "xscale=scaler_x.transform(data)\n",
    "yscale=scaler_y.transform(target)\n",
    "\n",
    "train_data, test_data, train_target, test_target = train_test_split(xscale, yscale,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.models as models\n",
    "import keras.layers as layers\n",
    "import keras.optimizers as optimizers\n",
    "from keras.layers import Dropout\n",
    "import numpy as np\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(128, input_dim=8, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',loss='mse',metrics=['mse','mae'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_79 (Dense)             (None, 128)               1152      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 18,965\n",
      "Trainable params: 18,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3221 samples, validate on 806 samples\n",
      "Epoch 1/200\n",
      "3221/3221 [==============================] - 0s 83us/step - loss: 0.0188 - mse: 0.0188 - mae: 0.0883 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0268\n",
      "Epoch 2/200\n",
      "3221/3221 [==============================] - 0s 39us/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0414 - val_loss: 6.2705e-04 - val_mse: 6.2705e-04 - val_mae: 0.0192\n",
      "Epoch 3/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0346 - val_loss: 5.2722e-04 - val_mse: 5.2722e-04 - val_mae: 0.0191\n",
      "Epoch 4/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0331 - val_loss: 2.2207e-04 - val_mse: 2.2207e-04 - val_mae: 0.0119\n",
      "Epoch 5/200\n",
      "3221/3221 [==============================] - 0s 39us/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0296 - val_loss: 3.4651e-04 - val_mse: 3.4651e-04 - val_mae: 0.0154\n",
      "Epoch 6/200\n",
      "3221/3221 [==============================] - 0s 39us/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0271 - val_loss: 3.1471e-04 - val_mse: 3.1471e-04 - val_mae: 0.0152\n",
      "Epoch 7/200\n",
      "3221/3221 [==============================] - 0s 38us/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0267 - val_loss: 8.6994e-04 - val_mse: 8.6994e-04 - val_mae: 0.0261\n",
      "Epoch 8/200\n",
      "3221/3221 [==============================] - 0s 38us/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0253 - val_loss: 9.9458e-05 - val_mse: 9.9458e-05 - val_mae: 0.0075\n",
      "Epoch 9/200\n",
      "3221/3221 [==============================] - 0s 38us/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0232 - val_loss: 2.4647e-04 - val_mse: 2.4647e-04 - val_mae: 0.0131\n",
      "Epoch 10/200\n",
      "3221/3221 [==============================] - 0s 38us/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0227 - val_loss: 2.7515e-04 - val_mse: 2.7515e-04 - val_mae: 0.0138\n",
      "Epoch 11/200\n",
      "3221/3221 [==============================] - 0s 38us/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0224 - val_loss: 1.0226e-04 - val_mse: 1.0226e-04 - val_mae: 0.0078\n",
      "Epoch 12/200\n",
      "3221/3221 [==============================] - 0s 38us/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0221 - val_loss: 2.8251e-04 - val_mse: 2.8251e-04 - val_mae: 0.0133\n",
      "Epoch 13/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 8.8764e-04 - mse: 8.8764e-04 - mae: 0.0203 - val_loss: 1.2982e-04 - val_mse: 1.2982e-04 - val_mae: 0.0091\n",
      "Epoch 14/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 8.3280e-04 - mse: 8.3280e-04 - mae: 0.0201 - val_loss: 9.9055e-05 - val_mse: 9.9055e-05 - val_mae: 0.0077\n",
      "Epoch 15/200\n",
      "3221/3221 [==============================] - 0s 38us/step - loss: 8.3499e-04 - mse: 8.3499e-04 - mae: 0.0199 - val_loss: 6.4297e-04 - val_mse: 6.4297e-04 - val_mae: 0.0179\n",
      "Epoch 16/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 8.9506e-04 - mse: 8.9506e-04 - mae: 0.0207 - val_loss: 2.0320e-04 - val_mse: 2.0320e-04 - val_mae: 0.0112\n",
      "Epoch 17/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 7.4931e-04 - mse: 7.4931e-04 - mae: 0.0187 - val_loss: 1.9630e-04 - val_mse: 1.9630e-04 - val_mae: 0.0108\n",
      "Epoch 18/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 7.0309e-04 - mse: 7.0309e-04 - mae: 0.0183 - val_loss: 1.1242e-04 - val_mse: 1.1242e-04 - val_mae: 0.0084\n",
      "Epoch 19/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 7.2895e-04 - mse: 7.2895e-04 - mae: 0.0188 - val_loss: 2.0153e-04 - val_mse: 2.0153e-04 - val_mae: 0.0108\n",
      "Epoch 20/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 8.7438e-04 - mse: 8.7438e-04 - mae: 0.0201 - val_loss: 2.0677e-04 - val_mse: 2.0677e-04 - val_mae: 0.0122\n",
      "Epoch 21/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 6.7606e-04 - mse: 6.7606e-04 - mae: 0.0182 - val_loss: 1.3318e-04 - val_mse: 1.3318e-04 - val_mae: 0.0093\n",
      "Epoch 22/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 6.3000e-04 - mse: 6.3000e-04 - mae: 0.0171 - val_loss: 1.9268e-04 - val_mse: 1.9268e-04 - val_mae: 0.0100\n",
      "Epoch 23/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 6.9362e-04 - mse: 6.9362e-04 - mae: 0.0181 - val_loss: 2.4869e-04 - val_mse: 2.4869e-04 - val_mae: 0.0126\n",
      "Epoch 24/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 5.8472e-04 - mse: 5.8472e-04 - mae: 0.0164 - val_loss: 7.6848e-05 - val_mse: 7.6848e-05 - val_mae: 0.0070\n",
      "Epoch 25/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 6.0554e-04 - mse: 6.0554e-04 - mae: 0.0168 - val_loss: 1.0962e-04 - val_mse: 1.0962e-04 - val_mae: 0.0089\n",
      "Epoch 26/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 5.8356e-04 - mse: 5.8356e-04 - mae: 0.0161 - val_loss: 8.2216e-05 - val_mse: 8.2216e-05 - val_mae: 0.0073\n",
      "Epoch 27/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 6.1070e-04 - mse: 6.1070e-04 - mae: 0.0172 - val_loss: 1.0608e-04 - val_mse: 1.0608e-04 - val_mae: 0.0083\n",
      "Epoch 28/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 5.5037e-04 - mse: 5.5037e-04 - mae: 0.0161 - val_loss: 2.1200e-04 - val_mse: 2.1200e-04 - val_mae: 0.0101\n",
      "Epoch 29/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 5.6652e-04 - mse: 5.6652e-04 - mae: 0.0167 - val_loss: 2.0749e-04 - val_mse: 2.0749e-04 - val_mae: 0.0110\n",
      "Epoch 30/200\n",
      "3221/3221 [==============================] - 0s 38us/step - loss: 5.3466e-04 - mse: 5.3466e-04 - mae: 0.0158 - val_loss: 1.7022e-04 - val_mse: 1.7022e-04 - val_mae: 0.0095\n",
      "Epoch 31/200\n",
      "3221/3221 [==============================] - 0s 38us/step - loss: 5.3905e-04 - mse: 5.3905e-04 - mae: 0.0164 - val_loss: 9.9613e-05 - val_mse: 9.9613e-05 - val_mae: 0.0077\n",
      "Epoch 32/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 5.7800e-04 - mse: 5.7800e-04 - mae: 0.0167 - val_loss: 1.2095e-04 - val_mse: 1.2095e-04 - val_mae: 0.0089\n",
      "Epoch 33/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 4.8712e-04 - mse: 4.8712e-04 - mae: 0.0154 - val_loss: 1.9889e-04 - val_mse: 1.9889e-04 - val_mae: 0.0104\n",
      "Epoch 34/200\n",
      "3221/3221 [==============================] - 0s 38us/step - loss: 5.3724e-04 - mse: 5.3724e-04 - mae: 0.0160 - val_loss: 1.6254e-04 - val_mse: 1.6254e-04 - val_mae: 0.0090\n",
      "Epoch 35/200\n",
      "3221/3221 [==============================] - 0s 38us/step - loss: 4.9053e-04 - mse: 4.9053e-04 - mae: 0.0152 - val_loss: 6.1893e-05 - val_mse: 6.1893e-05 - val_mae: 0.0059\n",
      "Epoch 36/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 5.0656e-04 - mse: 5.0656e-04 - mae: 0.0154 - val_loss: 9.9515e-05 - val_mse: 9.9515e-05 - val_mae: 0.0079\n",
      "Epoch 37/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 5.2718e-04 - mse: 5.2718e-04 - mae: 0.0156 - val_loss: 1.7975e-04 - val_mse: 1.7975e-04 - val_mae: 0.0108\n",
      "Epoch 38/200\n",
      "3221/3221 [==============================] - 0s 47us/step - loss: 4.9744e-04 - mse: 4.9744e-04 - mae: 0.0157 - val_loss: 2.5980e-04 - val_mse: 2.5980e-04 - val_mae: 0.0133\n",
      "Epoch 39/200\n",
      "3221/3221 [==============================] - 0s 44us/step - loss: 4.8605e-04 - mse: 4.8605e-04 - mae: 0.0148 - val_loss: 1.2767e-04 - val_mse: 1.2767e-04 - val_mae: 0.0094\n",
      "Epoch 40/200\n",
      "3221/3221 [==============================] - 0s 47us/step - loss: 5.0446e-04 - mse: 5.0446e-04 - mae: 0.0160 - val_loss: 5.7038e-04 - val_mse: 5.7038e-04 - val_mae: 0.0182\n",
      "Epoch 41/200\n",
      "3221/3221 [==============================] - 0s 44us/step - loss: 4.3671e-04 - mse: 4.3671e-04 - mae: 0.0145 - val_loss: 6.5444e-04 - val_mse: 6.5444e-04 - val_mae: 0.0186\n",
      "Epoch 42/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 4.0807e-04 - mse: 4.0807e-04 - mae: 0.0143 - val_loss: 2.6058e-04 - val_mse: 2.6058e-04 - val_mae: 0.0139\n",
      "Epoch 43/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 4.7150e-04 - mse: 4.7150e-04 - mae: 0.0151 - val_loss: 2.3835e-04 - val_mse: 2.3835e-04 - val_mae: 0.0132\n",
      "Epoch 44/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 4.1754e-04 - mse: 4.1754e-04 - mae: 0.0141 - val_loss: 1.9817e-04 - val_mse: 1.9817e-04 - val_mae: 0.0108\n",
      "Epoch 45/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 4.8166e-04 - mse: 4.8166e-04 - mae: 0.0151 - val_loss: 1.4491e-04 - val_mse: 1.4491e-04 - val_mae: 0.0099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 3.9812e-04 - mse: 3.9812e-04 - mae: 0.0143 - val_loss: 1.6794e-04 - val_mse: 1.6794e-04 - val_mae: 0.0107\n",
      "Epoch 47/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 4.3670e-04 - mse: 4.3670e-04 - mae: 0.0147 - val_loss: 1.0441e-04 - val_mse: 1.0441e-04 - val_mae: 0.0085\n",
      "Epoch 48/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 4.5861e-04 - mse: 4.5861e-04 - mae: 0.0148 - val_loss: 1.3508e-04 - val_mse: 1.3508e-04 - val_mae: 0.0095\n",
      "Epoch 49/200\n",
      "3221/3221 [==============================] - 0s 39us/step - loss: 4.2748e-04 - mse: 4.2748e-04 - mae: 0.0142 - val_loss: 3.1731e-04 - val_mse: 3.1731e-04 - val_mae: 0.0155\n",
      "Epoch 50/200\n",
      "3221/3221 [==============================] - 0s 45us/step - loss: 3.8599e-04 - mse: 3.8600e-04 - mae: 0.0135 - val_loss: 1.7420e-04 - val_mse: 1.7420e-04 - val_mae: 0.0102\n",
      "Epoch 51/200\n",
      "3221/3221 [==============================] - 0s 40us/step - loss: 4.1340e-04 - mse: 4.1340e-04 - mae: 0.0141 - val_loss: 2.8318e-04 - val_mse: 2.8318e-04 - val_mae: 0.0152\n",
      "Epoch 52/200\n",
      "3221/3221 [==============================] - 0s 35us/step - loss: 3.9469e-04 - mse: 3.9469e-04 - mae: 0.0137 - val_loss: 1.0983e-04 - val_mse: 1.0983e-04 - val_mae: 0.0088\n",
      "Epoch 53/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 3.8240e-04 - mse: 3.8240e-04 - mae: 0.0134 - val_loss: 1.7574e-04 - val_mse: 1.7574e-04 - val_mae: 0.0106\n",
      "Epoch 54/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 4.1436e-04 - mse: 4.1436e-04 - mae: 0.0136 - val_loss: 3.3066e-04 - val_mse: 3.3066e-04 - val_mae: 0.0160\n",
      "Epoch 55/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 3.6276e-04 - mse: 3.6276e-04 - mae: 0.0135 - val_loss: 1.4592e-04 - val_mse: 1.4592e-04 - val_mae: 0.0101\n",
      "Epoch 56/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 3.4358e-04 - mse: 3.4358e-04 - mae: 0.0128 - val_loss: 1.5205e-04 - val_mse: 1.5205e-04 - val_mae: 0.0103\n",
      "Epoch 57/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 3.9377e-04 - mse: 3.9377e-04 - mae: 0.0136 - val_loss: 1.1760e-04 - val_mse: 1.1760e-04 - val_mae: 0.0087\n",
      "Epoch 58/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 3.5075e-04 - mse: 3.5075e-04 - mae: 0.0128 - val_loss: 1.9059e-04 - val_mse: 1.9059e-04 - val_mae: 0.0122\n",
      "Epoch 59/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 3.9692e-04 - mse: 3.9692e-04 - mae: 0.0138 - val_loss: 1.7459e-04 - val_mse: 1.7459e-04 - val_mae: 0.0108\n",
      "Epoch 60/200\n",
      "3221/3221 [==============================] - 0s 38us/step - loss: 4.9572e-04 - mse: 4.9572e-04 - mae: 0.0154 - val_loss: 1.8860e-04 - val_mse: 1.8860e-04 - val_mae: 0.0111\n",
      "Epoch 61/200\n",
      "3221/3221 [==============================] - 0s 47us/step - loss: 3.2627e-04 - mse: 3.2627e-04 - mae: 0.0126 - val_loss: 1.6460e-04 - val_mse: 1.6460e-04 - val_mae: 0.0104\n",
      "Epoch 62/200\n",
      "3221/3221 [==============================] - 0s 52us/step - loss: 3.7315e-04 - mse: 3.7315e-04 - mae: 0.0131 - val_loss: 3.4693e-04 - val_mse: 3.4693e-04 - val_mae: 0.0147\n",
      "Epoch 63/200\n",
      "3221/3221 [==============================] - 0s 44us/step - loss: 3.2056e-04 - mse: 3.2056e-04 - mae: 0.0126 - val_loss: 5.0055e-04 - val_mse: 5.0055e-04 - val_mae: 0.0179\n",
      "Epoch 64/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 3.2216e-04 - mse: 3.2216e-04 - mae: 0.0126 - val_loss: 3.1088e-04 - val_mse: 3.1088e-04 - val_mae: 0.0149\n",
      "Epoch 65/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 3.2899e-04 - mse: 3.2899e-04 - mae: 0.0124 - val_loss: 1.9188e-04 - val_mse: 1.9188e-04 - val_mae: 0.0112\n",
      "Epoch 66/200\n",
      "3221/3221 [==============================] - 0s 40us/step - loss: 2.8474e-04 - mse: 2.8474e-04 - mae: 0.0114 - val_loss: 2.4004e-04 - val_mse: 2.4004e-04 - val_mae: 0.0123\n",
      "Epoch 67/200\n",
      "3221/3221 [==============================] - 0s 81us/step - loss: 3.2876e-04 - mse: 3.2876e-04 - mae: 0.0125 - val_loss: 2.7271e-04 - val_mse: 2.7271e-04 - val_mae: 0.0138\n",
      "Epoch 68/200\n",
      "3221/3221 [==============================] - 0s 72us/step - loss: 3.6461e-04 - mse: 3.6461e-04 - mae: 0.0133 - val_loss: 2.2076e-04 - val_mse: 2.2076e-04 - val_mae: 0.0117\n",
      "Epoch 69/200\n",
      "3221/3221 [==============================] - 0s 48us/step - loss: 3.5613e-04 - mse: 3.5613e-04 - mae: 0.0131 - val_loss: 2.1357e-04 - val_mse: 2.1357e-04 - val_mae: 0.0123\n",
      "Epoch 70/200\n",
      "3221/3221 [==============================] - 0s 41us/step - loss: 3.0238e-04 - mse: 3.0238e-04 - mae: 0.0117 - val_loss: 1.6400e-04 - val_mse: 1.6400e-04 - val_mae: 0.0105\n",
      "Epoch 71/200\n",
      "3221/3221 [==============================] - 0s 39us/step - loss: 2.8328e-04 - mse: 2.8328e-04 - mae: 0.0115 - val_loss: 1.8750e-04 - val_mse: 1.8750e-04 - val_mae: 0.0116\n",
      "Epoch 72/200\n",
      "3221/3221 [==============================] - 0s 44us/step - loss: 2.9589e-04 - mse: 2.9589e-04 - mae: 0.0120 - val_loss: 2.4863e-04 - val_mse: 2.4863e-04 - val_mae: 0.0129\n",
      "Epoch 73/200\n",
      "3221/3221 [==============================] - 0s 42us/step - loss: 2.7849e-04 - mse: 2.7849e-04 - mae: 0.0119 - val_loss: 2.3615e-04 - val_mse: 2.3615e-04 - val_mae: 0.0114\n",
      "Epoch 74/200\n",
      "3221/3221 [==============================] - 0s 45us/step - loss: 3.0806e-04 - mse: 3.0806e-04 - mae: 0.0120 - val_loss: 2.7170e-04 - val_mse: 2.7170e-04 - val_mae: 0.0133\n",
      "Epoch 75/200\n",
      "3221/3221 [==============================] - 0s 40us/step - loss: 2.6131e-04 - mse: 2.6131e-04 - mae: 0.0114 - val_loss: 3.3562e-04 - val_mse: 3.3562e-04 - val_mae: 0.0150\n",
      "Epoch 76/200\n",
      "3221/3221 [==============================] - 0s 42us/step - loss: 2.9557e-04 - mse: 2.9557e-04 - mae: 0.0119 - val_loss: 2.1788e-04 - val_mse: 2.1788e-04 - val_mae: 0.0119\n",
      "Epoch 77/200\n",
      "3221/3221 [==============================] - 0s 59us/step - loss: 3.0851e-04 - mse: 3.0851e-04 - mae: 0.0122 - val_loss: 2.1139e-04 - val_mse: 2.1139e-04 - val_mae: 0.0120\n",
      "Epoch 78/200\n",
      "3221/3221 [==============================] - 0s 72us/step - loss: 2.9639e-04 - mse: 2.9639e-04 - mae: 0.0119 - val_loss: 3.9327e-04 - val_mse: 3.9327e-04 - val_mae: 0.0161\n",
      "Epoch 79/200\n",
      "3221/3221 [==============================] - 0s 53us/step - loss: 3.3998e-04 - mse: 3.3998e-04 - mae: 0.0128 - val_loss: 1.9194e-04 - val_mse: 1.9194e-04 - val_mae: 0.0118\n",
      "Epoch 80/200\n",
      "3221/3221 [==============================] - 0s 45us/step - loss: 3.1680e-04 - mse: 3.1680e-04 - mae: 0.0124 - val_loss: 2.9501e-04 - val_mse: 2.9501e-04 - val_mae: 0.0148\n",
      "Epoch 81/200\n",
      "3221/3221 [==============================] - 0s 55us/step - loss: 2.5277e-04 - mse: 2.5277e-04 - mae: 0.0111 - val_loss: 3.0596e-04 - val_mse: 3.0596e-04 - val_mae: 0.0150\n",
      "Epoch 82/200\n",
      "3221/3221 [==============================] - 0s 69us/step - loss: 2.7539e-04 - mse: 2.7539e-04 - mae: 0.0115 - val_loss: 1.5598e-04 - val_mse: 1.5598e-04 - val_mae: 0.0098\n",
      "Epoch 83/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 2.7079e-04 - mse: 2.7079e-04 - mae: 0.0114 - val_loss: 1.6817e-04 - val_mse: 1.6817e-04 - val_mae: 0.0105\n",
      "Epoch 84/200\n",
      "3221/3221 [==============================] - 0s 38us/step - loss: 2.5790e-04 - mse: 2.5790e-04 - mae: 0.0112 - val_loss: 2.8527e-04 - val_mse: 2.8527e-04 - val_mae: 0.0147\n",
      "Epoch 85/200\n",
      "3221/3221 [==============================] - 0s 41us/step - loss: 3.0571e-04 - mse: 3.0571e-04 - mae: 0.0123 - val_loss: 2.3571e-04 - val_mse: 2.3571e-04 - val_mae: 0.0132\n",
      "Epoch 86/200\n",
      "3221/3221 [==============================] - 0s 43us/step - loss: 2.5317e-04 - mse: 2.5317e-04 - mae: 0.0112 - val_loss: 2.4001e-04 - val_mse: 2.4001e-04 - val_mae: 0.0130\n",
      "Epoch 87/200\n",
      "3221/3221 [==============================] - 0s 43us/step - loss: 2.4420e-04 - mse: 2.4420e-04 - mae: 0.0108 - val_loss: 2.3922e-04 - val_mse: 2.3922e-04 - val_mae: 0.0128\n",
      "Epoch 88/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 2.4727e-04 - mse: 2.4727e-04 - mae: 0.0110 - val_loss: 1.8954e-04 - val_mse: 1.8954e-04 - val_mae: 0.0113\n",
      "Epoch 89/200\n",
      "3221/3221 [==============================] - 0s 41us/step - loss: 2.8197e-04 - mse: 2.8197e-04 - mae: 0.0119 - val_loss: 2.4213e-04 - val_mse: 2.4213e-04 - val_mae: 0.0122\n",
      "Epoch 90/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3221/3221 [==============================] - 0s 44us/step - loss: 2.4717e-04 - mse: 2.4717e-04 - mae: 0.0110 - val_loss: 2.7185e-04 - val_mse: 2.7185e-04 - val_mae: 0.0139\n",
      "Epoch 91/200\n",
      "3221/3221 [==============================] - 0s 44us/step - loss: 2.4654e-04 - mse: 2.4654e-04 - mae: 0.0109 - val_loss: 2.5283e-04 - val_mse: 2.5283e-04 - val_mae: 0.0124\n",
      "Epoch 92/200\n",
      "3221/3221 [==============================] - 0s 43us/step - loss: 2.4593e-04 - mse: 2.4593e-04 - mae: 0.0113 - val_loss: 1.3972e-04 - val_mse: 1.3972e-04 - val_mae: 0.0098\n",
      "Epoch 93/200\n",
      "3221/3221 [==============================] - 0s 43us/step - loss: 2.2000e-04 - mse: 2.2000e-04 - mae: 0.0104 - val_loss: 2.1841e-04 - val_mse: 2.1841e-04 - val_mae: 0.0118\n",
      "Epoch 94/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 2.6647e-04 - mse: 2.6647e-04 - mae: 0.0111 - val_loss: 2.9636e-04 - val_mse: 2.9636e-04 - val_mae: 0.0139\n",
      "Epoch 95/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 2.3189e-04 - mse: 2.3189e-04 - mae: 0.0106 - val_loss: 2.3199e-04 - val_mse: 2.3199e-04 - val_mae: 0.0118\n",
      "Epoch 96/200\n",
      "3221/3221 [==============================] - 0s 41us/step - loss: 2.3075e-04 - mse: 2.3075e-04 - mae: 0.0109 - val_loss: 3.2318e-04 - val_mse: 3.2318e-04 - val_mae: 0.0149\n",
      "Epoch 97/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 2.1364e-04 - mse: 2.1364e-04 - mae: 0.0104 - val_loss: 2.0964e-04 - val_mse: 2.0964e-04 - val_mae: 0.0119\n",
      "Epoch 98/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 2.3122e-04 - mse: 2.3122e-04 - mae: 0.0108 - val_loss: 2.5575e-04 - val_mse: 2.5575e-04 - val_mae: 0.0133\n",
      "Epoch 99/200\n",
      "3221/3221 [==============================] - 0s 51us/step - loss: 2.6269e-04 - mse: 2.6269e-04 - mae: 0.0112 - val_loss: 2.4194e-04 - val_mse: 2.4194e-04 - val_mae: 0.0132\n",
      "Epoch 100/200\n",
      "3221/3221 [==============================] - 0s 51us/step - loss: 2.1842e-04 - mse: 2.1842e-04 - mae: 0.0105 - val_loss: 2.3961e-04 - val_mse: 2.3961e-04 - val_mae: 0.0128\n",
      "Epoch 101/200\n",
      "3221/3221 [==============================] - 0s 39us/step - loss: 2.3437e-04 - mse: 2.3437e-04 - mae: 0.0107 - val_loss: 2.2496e-04 - val_mse: 2.2496e-04 - val_mae: 0.0121\n",
      "Epoch 102/200\n",
      "3221/3221 [==============================] - 0s 39us/step - loss: 2.4059e-04 - mse: 2.4059e-04 - mae: 0.0109 - val_loss: 2.8833e-04 - val_mse: 2.8833e-04 - val_mae: 0.0140\n",
      "Epoch 103/200\n",
      "3221/3221 [==============================] - 0s 51us/step - loss: 2.5719e-04 - mse: 2.5719e-04 - mae: 0.0115 - val_loss: 2.9762e-04 - val_mse: 2.9762e-04 - val_mae: 0.0142\n",
      "Epoch 104/200\n",
      "3221/3221 [==============================] - 0s 44us/step - loss: 2.3458e-04 - mse: 2.3458e-04 - mae: 0.0104 - val_loss: 2.4127e-04 - val_mse: 2.4126e-04 - val_mae: 0.0123\n",
      "Epoch 105/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 2.0710e-04 - mse: 2.0710e-04 - mae: 0.0102 - val_loss: 3.1737e-04 - val_mse: 3.1737e-04 - val_mae: 0.0148\n",
      "Epoch 106/200\n",
      "3221/3221 [==============================] - 0s 40us/step - loss: 2.3501e-04 - mse: 2.3501e-04 - mae: 0.0110 - val_loss: 4.3467e-04 - val_mse: 4.3467e-04 - val_mae: 0.0174\n",
      "Epoch 107/200\n",
      "3221/3221 [==============================] - 0s 35us/step - loss: 2.4188e-04 - mse: 2.4188e-04 - mae: 0.0108 - val_loss: 3.5134e-04 - val_mse: 3.5134e-04 - val_mae: 0.0157\n",
      "Epoch 108/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 2.1754e-04 - mse: 2.1754e-04 - mae: 0.0107 - val_loss: 2.5342e-04 - val_mse: 2.5342e-04 - val_mae: 0.0132\n",
      "Epoch 109/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 2.2790e-04 - mse: 2.2790e-04 - mae: 0.0107 - val_loss: 2.8015e-04 - val_mse: 2.8015e-04 - val_mae: 0.0140\n",
      "Epoch 110/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 2.1064e-04 - mse: 2.1064e-04 - mae: 0.0103 - val_loss: 2.2197e-04 - val_mse: 2.2197e-04 - val_mae: 0.0124\n",
      "Epoch 111/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 2.4022e-04 - mse: 2.4022e-04 - mae: 0.0110 - val_loss: 2.9173e-04 - val_mse: 2.9173e-04 - val_mae: 0.0141\n",
      "Epoch 112/200\n",
      "3221/3221 [==============================] - 0s 35us/step - loss: 2.1227e-04 - mse: 2.1227e-04 - mae: 0.0101 - val_loss: 3.0381e-04 - val_mse: 3.0381e-04 - val_mae: 0.0146\n",
      "Epoch 113/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 2.0963e-04 - mse: 2.0963e-04 - mae: 0.0100 - val_loss: 2.1242e-04 - val_mse: 2.1242e-04 - val_mae: 0.0116\n",
      "Epoch 114/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 2.2272e-04 - mse: 2.2272e-04 - mae: 0.0104 - val_loss: 3.3807e-04 - val_mse: 3.3807e-04 - val_mae: 0.0148\n",
      "Epoch 115/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 2.1297e-04 - mse: 2.1297e-04 - mae: 0.0103 - val_loss: 2.0785e-04 - val_mse: 2.0785e-04 - val_mae: 0.0119\n",
      "Epoch 116/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.9861e-04 - mse: 1.9861e-04 - mae: 0.0099 - val_loss: 4.5146e-04 - val_mse: 4.5146e-04 - val_mae: 0.0179\n",
      "Epoch 117/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.9933e-04 - mse: 1.9933e-04 - mae: 0.0098 - val_loss: 1.8660e-04 - val_mse: 1.8660e-04 - val_mae: 0.0111\n",
      "Epoch 118/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.9988e-04 - mse: 1.9988e-04 - mae: 0.0104 - val_loss: 2.3997e-04 - val_mse: 2.3997e-04 - val_mae: 0.0128\n",
      "Epoch 119/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 1.9414e-04 - mse: 1.9414e-04 - mae: 0.0099 - val_loss: 2.7858e-04 - val_mse: 2.7858e-04 - val_mae: 0.0140\n",
      "Epoch 120/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 2.3243e-04 - mse: 2.3243e-04 - mae: 0.0111 - val_loss: 1.3445e-04 - val_mse: 1.3445e-04 - val_mae: 0.0097\n",
      "Epoch 121/200\n",
      "3221/3221 [==============================] - 0s 35us/step - loss: 1.9242e-04 - mse: 1.9242e-04 - mae: 0.0097 - val_loss: 2.3479e-04 - val_mse: 2.3479e-04 - val_mae: 0.0118\n",
      "Epoch 122/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.9490e-04 - mse: 1.9490e-04 - mae: 0.0097 - val_loss: 2.8462e-04 - val_mse: 2.8462e-04 - val_mae: 0.0138\n",
      "Epoch 123/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.8493e-04 - mse: 1.8493e-04 - mae: 0.0095 - val_loss: 2.6230e-04 - val_mse: 2.6230e-04 - val_mae: 0.0138\n",
      "Epoch 124/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 1.8880e-04 - mse: 1.8880e-04 - mae: 0.0097 - val_loss: 2.0293e-04 - val_mse: 2.0293e-04 - val_mae: 0.0115\n",
      "Epoch 125/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.8949e-04 - mse: 1.8949e-04 - mae: 0.0098 - val_loss: 2.4920e-04 - val_mse: 2.4920e-04 - val_mae: 0.0125\n",
      "Epoch 126/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 2.1327e-04 - mse: 2.1327e-04 - mae: 0.0105 - val_loss: 4.0084e-04 - val_mse: 4.0084e-04 - val_mae: 0.0176\n",
      "Epoch 127/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 2.3247e-04 - mse: 2.3247e-04 - mae: 0.0109 - val_loss: 3.3406e-04 - val_mse: 3.3406e-04 - val_mae: 0.0152\n",
      "Epoch 128/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.9706e-04 - mse: 1.9706e-04 - mae: 0.0102 - val_loss: 1.7845e-04 - val_mse: 1.7845e-04 - val_mae: 0.0112\n",
      "Epoch 129/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.8897e-04 - mse: 1.8897e-04 - mae: 0.0098 - val_loss: 1.7959e-04 - val_mse: 1.7959e-04 - val_mae: 0.0109\n",
      "Epoch 130/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.7452e-04 - mse: 1.7452e-04 - mae: 0.0093 - val_loss: 2.9004e-04 - val_mse: 2.9004e-04 - val_mae: 0.0140\n",
      "Epoch 131/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 1.9837e-04 - mse: 1.9837e-04 - mae: 0.0099 - val_loss: 2.5822e-04 - val_mse: 2.5822e-04 - val_mae: 0.0136\n",
      "Epoch 132/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 2.0084e-04 - mse: 2.0084e-04 - mae: 0.0099 - val_loss: 2.7444e-04 - val_mse: 2.7444e-04 - val_mae: 0.0136\n",
      "Epoch 133/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 2.0351e-04 - mse: 2.0351e-04 - mae: 0.0102 - val_loss: 3.0416e-04 - val_mse: 3.0416e-04 - val_mae: 0.0143\n",
      "Epoch 134/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.9046e-04 - mse: 1.9046e-04 - mae: 0.0096 - val_loss: 4.6550e-04 - val_mse: 4.6550e-04 - val_mae: 0.0188\n",
      "Epoch 135/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 2.0754e-04 - mse: 2.0754e-04 - mae: 0.0104 - val_loss: 4.4352e-04 - val_mse: 4.4352e-04 - val_mae: 0.0182\n",
      "Epoch 136/200\n",
      "3221/3221 [==============================] - 0s 41us/step - loss: 1.7536e-04 - mse: 1.7536e-04 - mae: 0.0094 - val_loss: 3.6209e-04 - val_mse: 3.6209e-04 - val_mae: 0.0156\n",
      "Epoch 137/200\n",
      "3221/3221 [==============================] - 0s 35us/step - loss: 2.2207e-04 - mse: 2.2207e-04 - mae: 0.0105 - val_loss: 3.3453e-04 - val_mse: 3.3453e-04 - val_mae: 0.0152\n",
      "Epoch 138/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.7936e-04 - mse: 1.7936e-04 - mae: 0.0095 - val_loss: 2.5138e-04 - val_mse: 2.5138e-04 - val_mae: 0.0130\n",
      "Epoch 139/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 1.7364e-04 - mse: 1.7364e-04 - mae: 0.0092 - val_loss: 3.2125e-04 - val_mse: 3.2125e-04 - val_mae: 0.0145\n",
      "Epoch 140/200\n",
      "3221/3221 [==============================] - 0s 35us/step - loss: 1.7072e-04 - mse: 1.7072e-04 - mae: 0.0093 - val_loss: 2.4130e-04 - val_mse: 2.4130e-04 - val_mae: 0.0122\n",
      "Epoch 141/200\n",
      "3221/3221 [==============================] - 0s 35us/step - loss: 1.9595e-04 - mse: 1.9595e-04 - mae: 0.0101 - val_loss: 3.4336e-04 - val_mse: 3.4336e-04 - val_mae: 0.0160\n",
      "Epoch 142/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 2.0513e-04 - mse: 2.0513e-04 - mae: 0.0100 - val_loss: 3.9063e-04 - val_mse: 3.9063e-04 - val_mae: 0.0163\n",
      "Epoch 143/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.5680e-04 - mse: 1.5680e-04 - mae: 0.0088 - val_loss: 4.0437e-04 - val_mse: 4.0437e-04 - val_mae: 0.0175\n",
      "Epoch 144/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.5764e-04 - mse: 1.5764e-04 - mae: 0.0089 - val_loss: 3.4350e-04 - val_mse: 3.4350e-04 - val_mae: 0.0153\n",
      "Epoch 145/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 1.4725e-04 - mse: 1.4725e-04 - mae: 0.0088 - val_loss: 4.1066e-04 - val_mse: 4.1066e-04 - val_mae: 0.0168\n",
      "Epoch 146/200\n",
      "3221/3221 [==============================] - 0s 35us/step - loss: 1.6858e-04 - mse: 1.6858e-04 - mae: 0.0095 - val_loss: 2.4118e-04 - val_mse: 2.4118e-04 - val_mae: 0.0125\n",
      "Epoch 147/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.7238e-04 - mse: 1.7238e-04 - mae: 0.0095 - val_loss: 3.2653e-04 - val_mse: 3.2653e-04 - val_mae: 0.0152\n",
      "Epoch 148/200\n",
      "3221/3221 [==============================] - 0s 40us/step - loss: 2.1341e-04 - mse: 2.1341e-04 - mae: 0.0104 - val_loss: 2.9206e-04 - val_mse: 2.9206e-04 - val_mae: 0.0140\n",
      "Epoch 149/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.6741e-04 - mse: 1.6741e-04 - mae: 0.0093 - val_loss: 3.0479e-04 - val_mse: 3.0479e-04 - val_mae: 0.0144\n",
      "Epoch 150/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.8260e-04 - mse: 1.8260e-04 - mae: 0.0094 - val_loss: 2.5845e-04 - val_mse: 2.5845e-04 - val_mae: 0.0137\n",
      "Epoch 151/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.6621e-04 - mse: 1.6621e-04 - mae: 0.0089 - val_loss: 3.1179e-04 - val_mse: 3.1179e-04 - val_mae: 0.0148\n",
      "Epoch 152/200\n",
      "3221/3221 [==============================] - 0s 35us/step - loss: 1.7015e-04 - mse: 1.7015e-04 - mae: 0.0091 - val_loss: 2.6657e-04 - val_mse: 2.6657e-04 - val_mae: 0.0136\n",
      "Epoch 153/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.9063e-04 - mse: 1.9063e-04 - mae: 0.0097 - val_loss: 2.2383e-04 - val_mse: 2.2383e-04 - val_mae: 0.0120\n",
      "Epoch 154/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.6945e-04 - mse: 1.6945e-04 - mae: 0.0091 - val_loss: 2.4492e-04 - val_mse: 2.4492e-04 - val_mae: 0.0133\n",
      "Epoch 155/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.6769e-04 - mse: 1.6769e-04 - mae: 0.0094 - val_loss: 3.2082e-04 - val_mse: 3.2082e-04 - val_mae: 0.0154\n",
      "Epoch 156/200\n",
      "3221/3221 [==============================] - 0s 35us/step - loss: 1.6049e-04 - mse: 1.6049e-04 - mae: 0.0089 - val_loss: 3.3379e-04 - val_mse: 3.3379e-04 - val_mae: 0.0153\n",
      "Epoch 157/200\n",
      "3221/3221 [==============================] - 0s 35us/step - loss: 1.6219e-04 - mse: 1.6219e-04 - mae: 0.0091 - val_loss: 3.5059e-04 - val_mse: 3.5059e-04 - val_mae: 0.0154\n",
      "Epoch 158/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.4106e-04 - mse: 1.4106e-04 - mae: 0.0085 - val_loss: 4.1597e-04 - val_mse: 4.1597e-04 - val_mae: 0.0176\n",
      "Epoch 159/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.8288e-04 - mse: 1.8288e-04 - mae: 0.0096 - val_loss: 5.8140e-04 - val_mse: 5.8140e-04 - val_mae: 0.0202\n",
      "Epoch 160/200\n",
      "3221/3221 [==============================] - 0s 40us/step - loss: 1.6282e-04 - mse: 1.6282e-04 - mae: 0.0091 - val_loss: 2.5510e-04 - val_mse: 2.5510e-04 - val_mae: 0.0132\n",
      "Epoch 161/200\n",
      "3221/3221 [==============================] - 0s 42us/step - loss: 1.4521e-04 - mse: 1.4521e-04 - mae: 0.0087 - val_loss: 4.1773e-04 - val_mse: 4.1773e-04 - val_mae: 0.0168\n",
      "Epoch 162/200\n",
      "3221/3221 [==============================] - 0s 39us/step - loss: 1.5454e-04 - mse: 1.5454e-04 - mae: 0.0089 - val_loss: 3.6134e-04 - val_mse: 3.6134e-04 - val_mae: 0.0168\n",
      "Epoch 163/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 1.8775e-04 - mse: 1.8775e-04 - mae: 0.0097 - val_loss: 2.8278e-04 - val_mse: 2.8278e-04 - val_mae: 0.0141\n",
      "Epoch 164/200\n",
      "3221/3221 [==============================] - 0s 39us/step - loss: 1.7393e-04 - mse: 1.7393e-04 - mae: 0.0092 - val_loss: 3.9389e-04 - val_mse: 3.9389e-04 - val_mae: 0.0171\n",
      "Epoch 165/200\n",
      "3221/3221 [==============================] - 0s 63us/step - loss: 1.8170e-04 - mse: 1.8170e-04 - mae: 0.0095 - val_loss: 4.1524e-04 - val_mse: 4.1524e-04 - val_mae: 0.0172\n",
      "Epoch 166/200\n",
      "3221/3221 [==============================] - 0s 44us/step - loss: 1.5698e-04 - mse: 1.5698e-04 - mae: 0.0089 - val_loss: 3.0919e-04 - val_mse: 3.0919e-04 - val_mae: 0.0147\n",
      "Epoch 167/200\n",
      "3221/3221 [==============================] - 0s 45us/step - loss: 1.4561e-04 - mse: 1.4561e-04 - mae: 0.0086 - val_loss: 4.2176e-04 - val_mse: 4.2176e-04 - val_mae: 0.0180\n",
      "Epoch 168/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 1.7756e-04 - mse: 1.7756e-04 - mae: 0.0094 - val_loss: 3.3368e-04 - val_mse: 3.3368e-04 - val_mae: 0.0150\n",
      "Epoch 169/200\n",
      "3221/3221 [==============================] - 0s 39us/step - loss: 1.5172e-04 - mse: 1.5172e-04 - mae: 0.0089 - val_loss: 4.2370e-04 - val_mse: 4.2370e-04 - val_mae: 0.0183\n",
      "Epoch 170/200\n",
      "3221/3221 [==============================] - 0s 42us/step - loss: 1.3976e-04 - mse: 1.3976e-04 - mae: 0.0083 - val_loss: 4.1898e-04 - val_mse: 4.1898e-04 - val_mae: 0.0170\n",
      "Epoch 171/200\n",
      "3221/3221 [==============================] - 0s 47us/step - loss: 1.8265e-04 - mse: 1.8265e-04 - mae: 0.0096 - val_loss: 2.8855e-04 - val_mse: 2.8855e-04 - val_mae: 0.0142\n",
      "Epoch 172/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.6603e-04 - mse: 1.6603e-04 - mae: 0.0093 - val_loss: 2.6891e-04 - val_mse: 2.6891e-04 - val_mae: 0.0140\n",
      "Epoch 173/200\n",
      "3221/3221 [==============================] - 0s 40us/step - loss: 1.6507e-04 - mse: 1.6507e-04 - mae: 0.0091 - val_loss: 3.2333e-04 - val_mse: 3.2333e-04 - val_mae: 0.0150\n",
      "Epoch 174/200\n",
      "3221/3221 [==============================] - 0s 44us/step - loss: 1.6621e-04 - mse: 1.6621e-04 - mae: 0.0090 - val_loss: 3.2451e-04 - val_mse: 3.2451e-04 - val_mae: 0.0152\n",
      "Epoch 175/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.4759e-04 - mse: 1.4759e-04 - mae: 0.0085 - val_loss: 4.3687e-04 - val_mse: 4.3687e-04 - val_mae: 0.0174\n",
      "Epoch 176/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.5309e-04 - mse: 1.5309e-04 - mae: 0.0088 - val_loss: 2.3717e-04 - val_mse: 2.3717e-04 - val_mae: 0.0130\n",
      "Epoch 177/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 1.5545e-04 - mse: 1.5545e-04 - mae: 0.0088 - val_loss: 3.3925e-04 - val_mse: 3.3925e-04 - val_mae: 0.0155\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3221/3221 [==============================] - 0s 38us/step - loss: 1.6049e-04 - mse: 1.6049e-04 - mae: 0.0089 - val_loss: 2.7970e-04 - val_mse: 2.7970e-04 - val_mae: 0.0138\n",
      "Epoch 179/200\n",
      "3221/3221 [==============================] - 0s 38us/step - loss: 1.6184e-04 - mse: 1.6184e-04 - mae: 0.0089 - val_loss: 3.7022e-04 - val_mse: 3.7022e-04 - val_mae: 0.0156\n",
      "Epoch 180/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.5429e-04 - mse: 1.5429e-04 - mae: 0.0087 - val_loss: 3.7628e-04 - val_mse: 3.7628e-04 - val_mae: 0.0163\n",
      "Epoch 181/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.4964e-04 - mse: 1.4964e-04 - mae: 0.0086 - val_loss: 3.5038e-04 - val_mse: 3.5038e-04 - val_mae: 0.0153\n",
      "Epoch 182/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.2476e-04 - mse: 1.2476e-04 - mae: 0.0079 - val_loss: 3.3781e-04 - val_mse: 3.3781e-04 - val_mae: 0.0155\n",
      "Epoch 183/200\n",
      "3221/3221 [==============================] - 0s 35us/step - loss: 1.6900e-04 - mse: 1.6900e-04 - mae: 0.0089 - val_loss: 5.5331e-04 - val_mse: 5.5331e-04 - val_mae: 0.0206\n",
      "Epoch 184/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.7075e-04 - mse: 1.7075e-04 - mae: 0.0092 - val_loss: 3.3537e-04 - val_mse: 3.3537e-04 - val_mae: 0.0153\n",
      "Epoch 185/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 1.8550e-04 - mse: 1.8550e-04 - mae: 0.0096 - val_loss: 2.8685e-04 - val_mse: 2.8685e-04 - val_mae: 0.0139\n",
      "Epoch 186/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 1.6561e-04 - mse: 1.6561e-04 - mae: 0.0092 - val_loss: 4.1411e-04 - val_mse: 4.1411e-04 - val_mae: 0.0174\n",
      "Epoch 187/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 1.6129e-04 - mse: 1.6129e-04 - mae: 0.0088 - val_loss: 2.5609e-04 - val_mse: 2.5609e-04 - val_mae: 0.0130\n",
      "Epoch 188/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.7044e-04 - mse: 1.7044e-04 - mae: 0.0094 - val_loss: 3.3646e-04 - val_mse: 3.3646e-04 - val_mae: 0.0159\n",
      "Epoch 189/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.4713e-04 - mse: 1.4713e-04 - mae: 0.0086 - val_loss: 4.6631e-04 - val_mse: 4.6631e-04 - val_mae: 0.0178\n",
      "Epoch 190/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.3106e-04 - mse: 1.3106e-04 - mae: 0.0081 - val_loss: 3.6037e-04 - val_mse: 3.6037e-04 - val_mae: 0.0160\n",
      "Epoch 191/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 1.5663e-04 - mse: 1.5663e-04 - mae: 0.0090 - val_loss: 4.6651e-04 - val_mse: 4.6651e-04 - val_mae: 0.0185\n",
      "Epoch 192/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 1.5474e-04 - mse: 1.5474e-04 - mae: 0.0088 - val_loss: 4.5046e-04 - val_mse: 4.5046e-04 - val_mae: 0.0187\n",
      "Epoch 193/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 1.4318e-04 - mse: 1.4318e-04 - mae: 0.0083 - val_loss: 2.9498e-04 - val_mse: 2.9498e-04 - val_mae: 0.0146\n",
      "Epoch 194/200\n",
      "3221/3221 [==============================] - 0s 40us/step - loss: 1.3317e-04 - mse: 1.3317e-04 - mae: 0.0082 - val_loss: 3.1283e-04 - val_mse: 3.1283e-04 - val_mae: 0.0149\n",
      "Epoch 195/200\n",
      "3221/3221 [==============================] - 0s 36us/step - loss: 1.3949e-04 - mse: 1.3949e-04 - mae: 0.0081 - val_loss: 5.3914e-04 - val_mse: 5.3914e-04 - val_mae: 0.0197\n",
      "Epoch 196/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 1.4304e-04 - mse: 1.4304e-04 - mae: 0.0084 - val_loss: 4.8581e-04 - val_mse: 4.8581e-04 - val_mae: 0.0185\n",
      "Epoch 197/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 1.4463e-04 - mse: 1.4463e-04 - mae: 0.0082 - val_loss: 4.4668e-04 - val_mse: 4.4668e-04 - val_mae: 0.0179\n",
      "Epoch 198/200\n",
      "3221/3221 [==============================] - 0s 35us/step - loss: 1.5258e-04 - mse: 1.5258e-04 - mae: 0.0084 - val_loss: 3.4532e-04 - val_mse: 3.4532e-04 - val_mae: 0.0158\n",
      "Epoch 199/200\n",
      "3221/3221 [==============================] - 0s 38us/step - loss: 1.4708e-04 - mse: 1.4708e-04 - mae: 0.0087 - val_loss: 5.1937e-04 - val_mse: 5.1937e-04 - val_mae: 0.0199\n",
      "Epoch 200/200\n",
      "3221/3221 [==============================] - 0s 37us/step - loss: 1.5836e-04 - mse: 1.5836e-04 - mae: 0.0088 - val_loss: 3.9618e-04 - val_mse: 3.9618e-04 - val_mae: 0.0168\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_data,train_target,epochs=200,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score: 0.9932678039152627\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "results=model.predict(test_data)\n",
    "\n",
    "r2=r2_score(test_target,results)\n",
    "print('r2 score:',r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Result: [[142.860001]]\n",
      "Predicted Result: [[144.81654]]\n",
      "Previous Date [[142.860001]]\n"
     ]
    }
   ],
   "source": [
    "result=model.predict([[test_data[0]]])\n",
    "actual = scaler_y.inverse_transform([test_target[0]]) \n",
    "predicted = scaler_y.inverse_transform(result)\n",
    "\n",
    "print('Actual Result:',actual)\n",
    "print('Predicted Result:',predicted)\n",
    "print('Previous Date',scaler_y.inverse_transform([test_target[0]]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Result: 391.56\n",
      "Predicted Result: [[389.23328]]\n"
     ]
    }
   ],
   "source": [
    "my_test_data=[399.74,401.48,2.34,1.06,1829,82.17,1,0]\n",
    "my_test_data=scaler_x.transform([my_test_data])\n",
    "result=model.predict(my_test_data)\n",
    "actual=391.56\n",
    "predicted = scaler_y.inverse_transform(result)\n",
    "\n",
    "print('Actual Result:',actual)\n",
    "print('Predicted Result:',predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'activation': 'relu', 'hidden_units': 64, 'optimizer': 'adam'}\n",
      "Best score:  -0.005905135858465056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_regression\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Define a Keras model builder function that takes in hyperparameters\n",
    "def build_model(hidden_units=32, activation='relu', optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_units, input_dim=train_data.shape[1], activation=activation))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "# Create a scikit-learn estimator using KerasRegressor\n",
    "model = KerasRegressor(build_fn=build_model, verbose=0)\n",
    "\n",
    "# Define the hyperparameter grid to search over\n",
    "param_grid = {'hidden_units': [16, 32, 64], 'activation': ['relu', 'sigmoid'], 'optimizer': ['adam', 'sgd']}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "\n",
    "# Generate some toy data\n",
    "\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search.fit(xscale, yscale)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
